让Hadoop跑在云端系列文章 之 克隆虚拟机增加Hadoop节点
=============

[让Hadoop跑在云端系列文章](http://blog.fens.me/series-hadoop-cloud/)，介绍了如何整合虚拟化和Hadoop，让Hadoop集群跑在VPS虚拟主机上，通过云向用户提供存储和计算的服务。

现在硬件越来越便宜，一台非品牌服务器，2颗24核CPU，配48G内存，2T的硬盘，已经降到2万块人民币以下了。这种配置如果简单地放几个web应用，显然是奢侈的浪费。就算是用来实现单节点的hadoop，对计算资源浪费也是非常高的。对于这么高性能的计算机，如何有效利用计算资源，就成为成本控制的一项重要议题了。

通过虚拟化技术，我们可以将一台服务器，拆分成12台VPS，每台2核CPU，4G内存，40G硬盘，并且支持资源重新分配。多么伟大的技术啊！现在我们有了12个节点的hadoop集群， 让Hadoop跑在云端，让世界加速。

#### 关于作者：

+ 张丹(Conan), 程序员Java,R,PHP,Javascript
+ weibo：@Conan_Z
+ blog: http://blog.fens.me
+ email: bsspirit@gmail.com

#### 转载请注明出处：
http://blog.fens.me/hadoop-base-kvm/

![克隆虚拟机增加Hadoop节点](http://blog.fens.me/wp-content/uploads/2013/07/clone-guest.png)

#### 前言

通过虚拟化技术，我们可轻松的增加或删除一台虚拟机。像hadoop技术，安装，配置，运维，管理都很复杂，如果能通过虚拟化技术，降低运维成本，是多么开心的一件事啊！设想一下，如果一个人能够管理1000个hadoop节点，那么小型公司也可以随随便便构建像百度，阿里一样的强大的计算集群环境。世界也许会更奇妙！

当然，本文并不是讲一个人如何管理1000个hadoop节点。但我会介绍一种方式，通过克隆虚拟机来增加Hadoop节点。也许在大家的实践操作中，就能做出一个人运维1000个节点集群的方案。

#### 目录 

1. 系统环境介绍
2. 克隆虚拟机
3. 完成2个节点的hadoop集群
